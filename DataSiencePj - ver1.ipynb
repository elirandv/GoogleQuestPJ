{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm as tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from bert_tokenization import bertTokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lable selected for our project:** \n",
    "answer_relevance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (10, 41)\n",
      "test shape = (10, 11)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'input/Data/'\n",
    "BERT_PATH = 'input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n",
    "tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "df_train = pd.read_csv(PATH+'train.csv')\n",
    "df_test = pd.read_csv(PATH+'test.csv')\n",
    "df_sub = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "##remove later!!!\n",
    "df_train = df_train[:10]\n",
    "df_test = df_test[:10]\n",
    "df_sub = df_sub[:10]\n",
    "\n",
    "print('train shape =', df_train.shape)\n",
    "print('test shape =', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA engineering:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.NaN handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa_id 0.0\n",
      "question_title 0.0\n",
      "question_body 0.0\n",
      "question_user_name 0.0\n",
      "question_user_page 0.0\n",
      "answer 0.0\n",
      "answer_user_name 0.0\n",
      "answer_user_page 0.0\n",
      "url 0.0\n",
      "category 0.0\n",
      "host 0.0\n",
      "question_asker_intent_understanding 0.0\n",
      "question_body_critical 0.0\n",
      "question_conversational 0.0\n",
      "question_expect_short_answer 0.0\n",
      "question_fact_seeking 0.0\n",
      "question_has_commonly_accepted_answer 0.0\n",
      "question_interestingness_others 0.0\n",
      "question_interestingness_self 0.0\n",
      "question_multi_intent 0.0\n",
      "question_not_really_a_question 0.0\n",
      "question_opinion_seeking 0.0\n",
      "question_type_choice 0.0\n",
      "question_type_compare 0.0\n",
      "question_type_consequence 0.0\n",
      "question_type_definition 0.0\n",
      "question_type_entity 0.0\n",
      "question_type_instructions 0.0\n",
      "question_type_procedure 0.0\n",
      "question_type_reason_explanation 0.0\n",
      "question_type_spelling 0.0\n",
      "question_well_written 0.0\n",
      "answer_helpful 0.0\n",
      "answer_level_of_information 0.0\n",
      "answer_plausible 0.0\n",
      "answer_relevance 0.0\n",
      "answer_satisfaction 0.0\n",
      "answer_type_instructions 0.0\n",
      "answer_type_procedure 0.0\n",
      "answer_type_reason_explanation 0.0\n",
      "answer_well_written 0.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for var in df_train.head(1):\n",
    "    for elem in df_train[var]:\n",
    "        if elem == 'NaN' :\n",
    "            count +=1    \n",
    "    print(var , count/df_train.shape[0])\n",
    "    count = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Extraction of 'host' and 'category' to 'sub_category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21a007e88c8>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "sns.countplot(x='category', data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['host']=df_train['host'].apply(lambda x:(x.replace(x ,x.split('.')[0])))\n",
    "df_test['host']=df_test['host'].apply(lambda x:(x.replace(x ,x.split('.')[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = df_train.columns.str.replace('host', 'sub_category')\n",
    "df_test.columns = df_test.columns.str.replace('host', 'sub_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we trying to figure out if category is redundent due to the sub category\n",
    "arr_sub_category = {}\n",
    "for sub in df_train['sub_category'].unique():\n",
    "    data = df_train[df_train['sub_category'] == sub]\n",
    "    arr = df_train[df_train['sub_category'] == sub]['category'].unique()\n",
    "    if len(arr) > 1:\n",
    "        arr_sub_category[sub] = arr\n",
    "        print(sub, arr)\n",
    "        #correlation between two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each sub_category found to be multiplied to more than one category \n",
    "#(in order to drop the category feature without loosing any important info)\n",
    "for key in arr_sub_category.keys():\n",
    "    for val in arr_sub_category[key]:\n",
    "        df_train[(df_train['sub_category'] == key) & (df_train['category'] == val)] = df_train[(df_train['sub_category'] == key) & (df_train['category'] == val)].apply(lambda x :x.replace(key, key+'_'+val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['photo' 'rpg' 'electronics' 'judaism' 'graphicdesign' 'stackoverflow'\n",
      " 'askubuntu' 'gaming' 'serverfault']\n"
     ]
    }
   ],
   "source": [
    "# checking\n",
    "print(df_train['sub_category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.features plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21b124fca08>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "sns.countplot(x='sub_category', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.correlation sorted list between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    " def corrank(X):## to think about relevant correlations (sub_c and lable?, is text coor is relevant?)\n",
    "        import itertools\n",
    "        dff = pd.DataFrame([[(i,j),X.corr().loc[i,j]] for i,j in list(itertools.combinations(X.corr(method = 'spearman'), 2))],columns=['pairs','corr'])    \n",
    "        print(dff.sort_values(by='corr',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 pairs      corr\n",
      "313  (question_type_compare, question_type_definition)  1.000000\n",
      "140  (question_fact_seeking, question_has_commonly_...  1.000000\n",
      "396   (question_type_procedure, answer_type_procedure)  0.990665\n",
      "189  (question_interestingness_others, question_int...  0.917211\n",
      "450            (answer_relevance, answer_satisfaction)  0.855414\n",
      "224  (question_interestingness_self, question_well_...  0.824089\n",
      "437    (answer_level_of_information, answer_plausible)  0.809831\n",
      "445            (answer_plausible, answer_satisfaction)  0.785667\n",
      "440  (answer_level_of_information, answer_type_inst...  0.773021\n",
      "444               (answer_plausible, answer_relevance)  0.761454\n",
      "49   (question_asker_intent_understanding, question...  0.715678\n",
      "430                 (answer_helpful, answer_plausible)  0.704970\n",
      "439  (answer_level_of_information, answer_satisfact...  0.702446\n",
      "202  (question_interestingness_others, question_wel...  0.671729\n",
      "95     (question_conversational, question_type_choice)  0.666667\n",
      "383  (question_type_instructions, answer_type_instr...  0.644458\n",
      "433         (answer_helpful, answer_type_instructions)  0.633761\n",
      "455    (answer_satisfaction, answer_type_instructions)  0.596709\n",
      "446       (answer_plausible, answer_type_instructions)  0.593496\n",
      "429      (answer_helpful, answer_level_of_information)  0.580343\n",
      "438    (answer_level_of_information, answer_relevance)  0.562878\n",
      "432              (answer_helpful, answer_satisfaction)  0.548773\n",
      "36   (question_asker_intent_understanding, question...  0.533967\n",
      "198  (question_interestingness_others, question_typ...  0.518860\n",
      "408  (question_type_reason_explanation, answer_type...  0.515751\n",
      "71   (question_body_critical, question_type_definit...  0.499512\n",
      "69     (question_body_critical, question_type_compare)  0.499512\n",
      "379  (question_type_instructions, answer_level_of_i...  0.476393\n",
      "290  (question_opinion_seeking, answer_type_instruc...  0.475736\n",
      "5       (qa_id, question_has_commonly_accepted_answer)  0.472007\n",
      "..                                                 ...       ...\n",
      "344   (question_type_consequence, answer_well_written)       NaN\n",
      "345   (question_type_definition, question_type_entity)       NaN\n",
      "349  (question_type_definition, question_type_spell...       NaN\n",
      "360  (question_type_entity, question_type_instructi...       NaN\n",
      "361    (question_type_entity, question_type_procedure)       NaN\n",
      "362  (question_type_entity, question_type_reason_ex...       NaN\n",
      "363     (question_type_entity, question_type_spelling)       NaN\n",
      "364      (question_type_entity, question_well_written)       NaN\n",
      "365             (question_type_entity, answer_helpful)       NaN\n",
      "366  (question_type_entity, answer_level_of_informa...       NaN\n",
      "367           (question_type_entity, answer_plausible)       NaN\n",
      "368           (question_type_entity, answer_relevance)       NaN\n",
      "369        (question_type_entity, answer_satisfaction)       NaN\n",
      "370   (question_type_entity, answer_type_instructions)       NaN\n",
      "371      (question_type_entity, answer_type_procedure)       NaN\n",
      "372  (question_type_entity, answer_type_reason_expl...       NaN\n",
      "373        (question_type_entity, answer_well_written)       NaN\n",
      "376  (question_type_instructions, question_type_spe...       NaN\n",
      "388  (question_type_procedure, question_type_spelling)       NaN\n",
      "399  (question_type_reason_explanation, question_ty...       NaN\n",
      "410    (question_type_spelling, question_well_written)       NaN\n",
      "411           (question_type_spelling, answer_helpful)       NaN\n",
      "412  (question_type_spelling, answer_level_of_infor...       NaN\n",
      "413         (question_type_spelling, answer_plausible)       NaN\n",
      "414         (question_type_spelling, answer_relevance)       NaN\n",
      "415      (question_type_spelling, answer_satisfaction)       NaN\n",
      "416  (question_type_spelling, answer_type_instructi...       NaN\n",
      "417    (question_type_spelling, answer_type_procedure)       NaN\n",
      "418  (question_type_spelling, answer_type_reason_ex...       NaN\n",
      "419      (question_type_spelling, answer_well_written)       NaN\n",
      "\n",
      "[465 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "corrank(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.tokenization?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.**Categorizing questions**\n",
    "#HowTo - instructions (looking for actions in the answer)\n",
    "#Why \n",
    "#What / which kind of - classification\n",
    "#what is better - comparison\n",
    "#when / how often - time\n",
    "#what/ how many/ how much - quantative\n",
    "#where - places\n",
    "#who / whom - person\n",
    "#how does / how are - comprehension\n",
    "#can/ could - capability\n",
    "#should /would you/ do you want / is, are, am / does- Yes/No questions, willing\n",
    "#aren't you? wasn't it? - tag questions (in YES/NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_a = np.array([['Can an affidavit be used in Beit Din?', 10], ['How can I write HTML and send as an email?', 15], ['How do I remove a Facebook app request?', 14], ['How do you grapple in Dead Rising 3?', 1], ['How do you make a binary image in Photoshop?', 1]]) \n",
    "# df_a = pd.DataFrame(data_a)\n",
    "# df_a.columns = [\"question\", \"num\"]\n",
    "# print(df_a)\n",
    "\n",
    "# from adam_qas import adam_script as adam\n",
    "# dfOut = pd.DataFrame(np.array([[\"\",\"\",\"\"]]))\n",
    "# dfOut.columns = [\"q_class\",\"q_keywords\",\"quary\"]\n",
    "# dfOut = dfOut[:-1]\n",
    "# new_features = adam.activate(df_a['question'], dfOut)\n",
    "# print(new_features.head(2))\n",
    "# df_a.join(new_features)\n",
    "# print(df_a.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling adam's algorithem to produce new features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from adam_qas import adam_script as adam\n",
    "# dfOut = pd.DataFrame(np.array([[\"\",\"\",\"\"]]))\n",
    "# dfOut.columns = [\"q_class\",\"q_keywords\",\"quary\"]\n",
    "# dfOut = dfOut[:-1]\n",
    "\n",
    "# new_features = adam.activate(df_train['question_title'], dfOut)\n",
    "# print(new_features)\n",
    "\n",
    "# df_new_train=pd.concat([df_train,new_features], axis=1, sort=False)\n",
    "# df_new_test=pd.concat([df_test,new_features], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_train.to_csv(PATH+'df_new_train.csv', index=False)\n",
    "# df_new_test.to_csv(PATH+'df_new_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?.Redefine the features passed to the input categories - add sub_categoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "output categories:\n",
      "\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "input categories:\n",
      "\t ['question_title', 'question_body', 'answer', 'sub_category', 'q_class', 'q_keywords', 'quary']\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(PATH+'df_new_test.csv')\n",
    "df_train = pd.read_csv(PATH+'df_new_train.csv')\n",
    "output_categories = list(df_train.columns[11:41])\n",
    "# input_categories = list(df_train.columns[[1,2,5]])#orogional code\n",
    "input_categories = list(df_train.columns[[1,2,5,10,41,42,43]]) # we added the sub_categoty!\n",
    "print('\\noutput categories:\\n\\t', output_categories)\n",
    "print('\\ninput categories:\\n\\t', input_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, sub_category, q_class, q_keywords, quary, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=111, a_max_len=111, s_c_max_len=30, q_c_max_len=10, q_k_max_len=106, qu_max_len=106):\n",
    "\n",
    "    t   = tokenizer.tokenize(title)\n",
    "    q   = tokenizer.tokenize(question)\n",
    "    a   = tokenizer.tokenize(answer)\n",
    "    s_c = tokenizer.tokenize(sub_category)\n",
    "    q_c = tokenizer.tokenize(q_class)\n",
    "    q_k = tokenizer.tokenize(q_keywords)\n",
    "    qu  = tokenizer.tokenize(quary)\n",
    "    \n",
    "    t_len   = len(t)\n",
    "    q_len   = len(q)\n",
    "    a_len   = len(a)\n",
    "    s_c_len = len(s_c)\n",
    "    q_c_len = len(q_c)\n",
    "    q_k_len = len(q_k)\n",
    "    qu_len  = len(qu)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > (max_sequence_length/2):\n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "        \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length/2:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length/2, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        t   = t[:t_new_len]\n",
    "        q   = q[:q_new_len]\n",
    "        a   = a[:a_new_len]\n",
    "    \n",
    "    if (s_c_len+q_c_len+q_k_len+qu_len+4) > (max_sequence_length/2):\n",
    "        if s_c_max_len > s_c_len:\n",
    "            s_c_new_len = s_c_len\n",
    "            q_k_max_len = q_k_max_len + floor((s_c_max_len - s_c_len)/2)\n",
    "            qu_max_len = qu_max_len + ceil((s_c_max_len - s_c_len)/2)\n",
    "        else:\n",
    "            s_c_new_len = s_c_max_len\n",
    "        \n",
    "        if q_c_max_len > q_c_len:\n",
    "            q_c_new_len = q_c_len\n",
    "            q_k_max_len = q_k_max_len + floor((q_c_max_len - q_c_len)/2)\n",
    "            qu_max_len = qu_max_len + ceil((q_c_max_len - q_c_len)/2)\n",
    "        else:\n",
    "            q_c_new_len = q_c_max_len\n",
    "      \n",
    "        if q_k_max_len > q_k_len:\n",
    "            q_k_new_len = q_k_len \n",
    "            qu_new_len = qu_max_len + (q_k_max_len - q_k_len)\n",
    "        elif qu_max_len > qu_len:\n",
    "            q_k_new_len = q_k_max_len + (qu_max_len - qu_len)\n",
    "            qu_new_len = qu_len\n",
    "        else:\n",
    "            q_k_new_len = q_k_max_len\n",
    "            qu_new_len = qu_max_len\n",
    "            \n",
    "        if s_c_new_len+q_c_new_len+q_k_new_len+qu_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length/2, (s_c_new_len+q_c_new_len+q_k_new_len+qu_new_len+4)))\n",
    "        s_c = s_c[:s_c_new_len]\n",
    "        q_c = q_c[:q_c_new_len]\n",
    "        q_k = q_k[:q_k_new_len]\n",
    "        qu  = qu[:qu_new_len]\n",
    "    \n",
    "    return t, q, a, s_c, q_c, q_k, qu\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, sub_category, q_class, q_keywords, quary, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"] + sub_category + [\"[SEP]\"] + q_class + [\"[SEP]\"] + q_keywords + [\"[SEP]\"] + quary + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "\n",
    "    for index, instance in df[columns].iterrows():\n",
    "        t, q, a, s_c, q_c, q_k, qu = instance.question_title, instance.question_body, instance.answer, instance.sub_category, instance.q_class, instance.q_keywords, instance.quary\n",
    "\n",
    "        t, q, a, s_c, q_c, q_k, qu = _trim_input(t, q, a, s_c, q_c, q_k, qu, max_sequence_length)\n",
    "       \n",
    "       \n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, s_c, q_c, q_k, qu, tokenizer, max_sequence_length)\n",
    "        \n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.valid_predictions.append(\n",
    "            self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n",
    "        \n",
    "        rho_val = compute_spearmanr(\n",
    "            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        \n",
    "        print(\"\\nvalidation rho: %.4f\" % rho_val)\n",
    "        \n",
    "        if self.fold is not None:\n",
    "            self.model.save_weights(f'bert-base-{fold}-{epoch}.h5py')\n",
    "        \n",
    "        self.test_predictions.append(\n",
    "            self.model.predict(self.test_inputs, batch_size=self.batch_size)\n",
    "        )\n",
    "\n",
    "def bert_model():\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments], outputs=out)\n",
    "    \n",
    "    return model    \n",
    "        \n",
    "def train_and_predict(model, train_data, valid_data, test_data, \n",
    "                      learning_rate, epochs, batch_size, loss_function, fold):\n",
    "        \n",
    "    custom_callback = CustomCallback(\n",
    "        valid_data=(valid_data[0], valid_data[1]), \n",
    "        test_data=test_data,\n",
    "        batch_size=batch_size,\n",
    "        fold=None)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    model.fit(train_data[0], train_data[1], epochs=epochs, \n",
    "              batch_size=batch_size, callbacks=[custom_callback])\n",
    "    \n",
    "    return custom_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=10).split(X=df_train.question_body, groups=df_train.question_body) ############## originaln_splits=10\n",
    "\n",
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "inputs = compute_input_arays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-0077f2eee1d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                           \u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                           \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                           loss_function='binary_crossentropy', fold=fold)\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-176-2e04cb9c9c74>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[1;34m(model, train_data, valid_data, test_data, learning_rate, epochs, batch_size, loss_function, fold)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     model.fit(train_data[0], train_data[1], epochs=epochs, \n\u001b[1;32m---> 74\u001b[1;33m               batch_size=batch_size, callbacks=[custom_callback])\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    \n",
    "    # will actually only do 3 folds (out of 5) to manage < 2h\n",
    "    if fold < 3:\n",
    "        K.clear_session()\n",
    "        model = bert_model()\n",
    "\n",
    "        train_inputs = [inputs[i][train_idx] for i in range(3)]\n",
    "        train_outputs = outputs[train_idx]\n",
    "\n",
    "        valid_inputs = [inputs[i][valid_idx] for i in range(3)]\n",
    "        valid_outputs = outputs[valid_idx]\n",
    "\n",
    "        # history contains two lists of valid and test preds respectively:\n",
    "        #  [valid_predictions_{fold}, test_predictions_{fold}]\n",
    "        history = train_and_predict(model, \n",
    "                          train_data=(train_inputs, train_outputs), \n",
    "                          valid_data=(valid_inputs, valid_outputs),\n",
    "                          test_data=test_inputs, \n",
    "                          learning_rate=3e-5, epochs=5, batch_size=8,\n",
    "                          loss_function='binary_crossentropy', fold=fold)\n",
    "\n",
    "        histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = [histories[i].test_predictions for i in range(len(histories))]\n",
    "# test_predictions = [np.average(test_predictions[i], axis=0) for i in range(len(test_predictions))]\n",
    "# test_predictions = np.mean(test_predictions, axis=0)\n",
    "\n",
    "# df_sub =df_sub.assign(results = test_predictions)\n",
    "# print(df_sub)\n",
    "# df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
