{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from bert_tokenization import bertTokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lable selected for our project:** \n",
    "answer_relevance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (20, 41)\n",
      "test shape = (20, 11)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'input/Data/'\n",
    "BERT_PATH = 'input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n",
    "tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "df_train = pd.read_csv(PATH+'train.csv')\n",
    "df_test = pd.read_csv(PATH+'test.csv')\n",
    "df_sub = pd.read_csv(PATH+'sample_submission.csv')\n",
    "\n",
    "##remove later!!!\n",
    "df_train = df_train[:20]\n",
    "df_test = df_test[:20]\n",
    "df_sub = df_sub[:20]\n",
    "\n",
    "print('train shape =', df_train.shape)\n",
    "print('test shape =', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA engineering:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.NaN handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa_id 0.0\n",
      "question_title 0.0\n",
      "question_body 0.0\n",
      "question_user_name 0.0\n",
      "question_user_page 0.0\n",
      "answer 0.0\n",
      "answer_user_name 0.0\n",
      "answer_user_page 0.0\n",
      "url 0.0\n",
      "category 0.0\n",
      "host 0.0\n",
      "question_asker_intent_understanding 0.0\n",
      "question_body_critical 0.0\n",
      "question_conversational 0.0\n",
      "question_expect_short_answer 0.0\n",
      "question_fact_seeking 0.0\n",
      "question_has_commonly_accepted_answer 0.0\n",
      "question_interestingness_others 0.0\n",
      "question_interestingness_self 0.0\n",
      "question_multi_intent 0.0\n",
      "question_not_really_a_question 0.0\n",
      "question_opinion_seeking 0.0\n",
      "question_type_choice 0.0\n",
      "question_type_compare 0.0\n",
      "question_type_consequence 0.0\n",
      "question_type_definition 0.0\n",
      "question_type_entity 0.0\n",
      "question_type_instructions 0.0\n",
      "question_type_procedure 0.0\n",
      "question_type_reason_explanation 0.0\n",
      "question_type_spelling 0.0\n",
      "question_well_written 0.0\n",
      "answer_helpful 0.0\n",
      "answer_level_of_information 0.0\n",
      "answer_plausible 0.0\n",
      "answer_relevance 0.0\n",
      "answer_satisfaction 0.0\n",
      "answer_type_instructions 0.0\n",
      "answer_type_procedure 0.0\n",
      "answer_type_reason_explanation 0.0\n",
      "answer_well_written 0.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for var in df_train.head(1):\n",
    "    for elem in df_train[var]:\n",
    "        if elem == 'NaN' :\n",
    "            count +=1    \n",
    "    print(var , count/df_train.shape[0])\n",
    "    count = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Extraction of 'host' and 'category' to 'sub_category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fdbb81b288>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "sns.countplot(x='category', data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['host']=df_train['host'].apply(lambda x:(x.replace(x ,x.split('.')[0])))\n",
    "df_test['host']=df_test['host'].apply(lambda x:(x.replace(x ,x.split('.')[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = df_train.columns.str.replace('host', 'sub_category')\n",
    "df_test.columns = df_test.columns.str.replace('host', 'sub_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we trying to figure out if category is redundent due to the sub category\n",
    "arr_sub_category = {}\n",
    "for sub in df_train['sub_category'].unique():\n",
    "    data = df_train[df_train['sub_category'] == sub]\n",
    "    arr = df_train[df_train['sub_category'] == sub]['category'].unique()\n",
    "    if len(arr) > 1:\n",
    "        arr_sub_category[sub] = arr\n",
    "        print(sub, arr)\n",
    "        #correlation between two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each sub_category found to be multiplied to more than one category \n",
    "#(in order to drop the category feature without loosing any important info)\n",
    "for key in arr_sub_category.keys():\n",
    "    for val in arr_sub_category[key]:\n",
    "        df_train[(df_train['sub_category'] == key) & (df_train['category'] == val)] = df_train[(df_train['sub_category'] == key) & (df_train['category'] == val)].apply(lambda x :x.replace(key, key+'_'+val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['photo' 'rpg' 'electronics' 'judaism' 'graphicdesign' 'stackoverflow'\n",
      " 'askubuntu' 'gaming' 'serverfault' 'unix' 'dba' 'codereview' 'crypto'\n",
      " 'tex' 'travel' 'webapps']\n"
     ]
    }
   ],
   "source": [
    "# checking\n",
    "print(df_train['sub_category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.features plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fdb02a6b08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "sns.countplot(x='sub_category', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.correlation sorted list between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " def corrank(X):## to think about relevant correlations (sub_c and lable?, is text coor is relevant?)\n",
    "        import itertools\n",
    "        dff = pd.DataFrame([[(i,j),X.corr().loc[i,j]] for i,j in list(itertools.combinations(X.corr(method = 'spearman'), 2))],columns=['pairs','corr'])    \n",
    "        print(dff.sort_values(by='corr',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 pairs      corr\n",
      "313  (question_type_compare, question_type_definition)  0.889824\n",
      "396   (question_type_procedure, answer_type_procedure)  0.827768\n",
      "430                 (answer_helpful, answer_plausible)  0.825270\n",
      "189  (question_interestingness_others, question_int...  0.696985\n",
      "450            (answer_relevance, answer_satisfaction)  0.676171\n",
      "408  (question_type_reason_explanation, answer_type...  0.671200\n",
      "444               (answer_plausible, answer_relevance)  0.665221\n",
      "202  (question_interestingness_others, question_wel...  0.632998\n",
      "224  (question_interestingness_self, question_well_...  0.617930\n",
      "439  (answer_level_of_information, answer_satisfact...  0.616946\n",
      "383  (question_type_instructions, answer_type_instr...  0.607367\n",
      "285         (question_opinion_seeking, answer_helpful)  0.564762\n",
      "287       (question_opinion_seeking, answer_plausible)  0.516165\n",
      "77     (question_body_critical, question_well_written)  0.502469\n",
      "454            (answer_relevance, answer_well_written)  0.499504\n",
      "458         (answer_satisfaction, answer_well_written)  0.498116\n",
      "61     (question_body_critical, question_fact_seeking)  0.463196\n",
      "445            (answer_plausible, answer_satisfaction)  0.456432\n",
      "82       (question_body_critical, answer_satisfaction)  0.450791\n",
      "69     (question_body_critical, question_type_compare)  0.430403\n",
      "440  (answer_level_of_information, answer_type_inst...  0.429778\n",
      "374  (question_type_instructions, question_type_pro...  0.400437\n",
      "140  (question_fact_seeking, question_has_commonly_...  0.397360\n",
      "438    (answer_level_of_information, answer_relevance)  0.395398\n",
      "36   (question_asker_intent_understanding, question...  0.394053\n",
      "175  (question_has_commonly_accepted_answer, questi...  0.387783\n",
      "384  (question_type_instructions, answer_type_proce...  0.379485\n",
      "431                 (answer_helpful, answer_relevance)  0.376829\n",
      "369        (question_type_entity, answer_satisfaction)  0.375249\n",
      "432              (answer_helpful, answer_satisfaction)  0.368834\n",
      "..                                                 ...       ...\n",
      "330  (question_type_consequence, question_type_entity)       NaN\n",
      "331  (question_type_consequence, question_type_inst...       NaN\n",
      "332  (question_type_consequence, question_type_proc...       NaN\n",
      "333  (question_type_consequence, question_type_reas...       NaN\n",
      "334  (question_type_consequence, question_type_spel...       NaN\n",
      "335  (question_type_consequence, question_well_writ...       NaN\n",
      "336        (question_type_consequence, answer_helpful)       NaN\n",
      "337  (question_type_consequence, answer_level_of_in...       NaN\n",
      "338      (question_type_consequence, answer_plausible)       NaN\n",
      "339      (question_type_consequence, answer_relevance)       NaN\n",
      "340   (question_type_consequence, answer_satisfaction)       NaN\n",
      "341  (question_type_consequence, answer_type_instru...       NaN\n",
      "342  (question_type_consequence, answer_type_proced...       NaN\n",
      "343  (question_type_consequence, answer_type_reason...       NaN\n",
      "344   (question_type_consequence, answer_well_written)       NaN\n",
      "349  (question_type_definition, question_type_spell...       NaN\n",
      "363     (question_type_entity, question_type_spelling)       NaN\n",
      "376  (question_type_instructions, question_type_spe...       NaN\n",
      "388  (question_type_procedure, question_type_spelling)       NaN\n",
      "399  (question_type_reason_explanation, question_ty...       NaN\n",
      "410    (question_type_spelling, question_well_written)       NaN\n",
      "411           (question_type_spelling, answer_helpful)       NaN\n",
      "412  (question_type_spelling, answer_level_of_infor...       NaN\n",
      "413         (question_type_spelling, answer_plausible)       NaN\n",
      "414         (question_type_spelling, answer_relevance)       NaN\n",
      "415      (question_type_spelling, answer_satisfaction)       NaN\n",
      "416  (question_type_spelling, answer_type_instructi...       NaN\n",
      "417    (question_type_spelling, answer_type_procedure)       NaN\n",
      "418  (question_type_spelling, answer_type_reason_ex...       NaN\n",
      "419      (question_type_spelling, answer_well_written)       NaN\n",
      "\n",
      "[465 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "corrank(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.tokenization?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.**Categorizing questions**\n",
    "#HowTo - instructions (looking for actions in the answer)\n",
    "#Why \n",
    "#What / which kind of - classification\n",
    "#what is better - comparison\n",
    "#when / how often - time\n",
    "#what/ how many/ how much - quantative\n",
    "#where - places\n",
    "#who / whom - person\n",
    "#how does / how are - comprehension\n",
    "#can/ could - capability\n",
    "#should /would you/ do you want / is, are, am / does- Yes/No questions, willing\n",
    "#aren't you? wasn't it? - tag questions (in YES/NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     question num\n",
      "0       Can an affidavit be used in Beit Din?  10\n",
      "1  How can I write HTML and send as an email?  15\n"
     ]
    }
   ],
   "source": [
    "# data_a = np.array([['Can an affidavit be used in Beit Din?', 10], ['How can I write HTML and send as an email?', 15], ['How do I remove a Facebook app request?', 14], ['How do you grapple in Dead Rising 3?', 1], ['How do you make a binary image in Photoshop?', 1]]) \n",
    "data_a = np.array([['Can an affidavit be used in Beit Din?', 10], ['How can I write HTML and send as an email?', 15],]) \n",
    "df_a = pd.DataFrame(data_a)\n",
    "df_a.columns = [\"question\", \"num\"]\n",
    "print(df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:adam_qas.adam_script:WH :  | WH-POS :  | WH-NBOR-POS :  | Root-POS : VBN\n",
      "DEBUG:adam_qas.adam_script:Union Columns: 66\n",
      "DEBUG:adam_qas.adam_script:Training data: (5365, 66)\n",
      "DEBUG:adam_qas.adam_script:Target data: (1, 66)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator LinearSVC from version 0.19.1 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "DEBUG:adam_qas.adam_script:Classifier: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "INFO:__main__:Question Class: ['HUM']\n",
      "DEBUG:qas.feature_extractor:Compound Noun:affidavit DEP nsubjpass\n",
      "DEBUG:qas.feature_extractor:Compound Noun:Din DEP pobj\n",
      "INFO:__main__:Question Features: ['affidavit', 'Beit Din', 'use']\n",
      "INFO:__main__:Query: [{Features: ['affidavit', 'Beit Din', 'use'] ,Conjunction: [] ,Negations: [] ,Marker: []}]\n",
      "DEBUG:adam_qas.adam_script:WH : How | WH-POS : WRB | WH-NBOR-POS : MD | Root-POS : VB\n",
      "DEBUG:adam_qas.adam_script:Union Columns: 63\n",
      "DEBUG:adam_qas.adam_script:Training data: (5365, 63)\n",
      "DEBUG:adam_qas.adam_script:Target data: (1, 63)\n",
      "DEBUG:adam_qas.adam_script:Classifier: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "INFO:__main__:Question Class: ['DESC']\n",
      "DEBUG:qas.feature_extractor:Compound Noun:HTML DEP dobj\n",
      "DEBUG:qas.feature_extractor:Compound Noun:email DEP pobj\n",
      "INFO:__main__:Question Features: ['HTML', 'email', 'write']\n",
      "DEBUG:qas.query_const:Conjunction: `and` at 5\n",
      "DEBUG:qas.query_const:Conjuncting: ['write', 'send']\n",
      "INFO:__main__:Query: [{Features: ['HTML', 'email', 'write'] ,Conjunction: [['write', 'send'], 'and'] ,Negations: [] ,Marker: []}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [{Features: ['affidavit', 'Beit Din', 'use'] ,...\n",
      "1    [{Features: ['HTML', 'email', 'write'] ,Conjun...\n",
      "Name: quary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from adam_qas import adam_script as adam\n",
    "dfOut = pd.DataFrame(np.array([[\"\",\"\",\"\"]]))\n",
    "dfOut.columns = [\"q_class\",\"q_keywords\",\"quary\"]\n",
    "dfOut = dfOut[:-1]\n",
    "new_features = adam.activate(df_a['question'], dfOut)\n",
    "print(new_features['quary'])\n",
    "# df_train.join(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?.Redefine the features passed to the input categories - add sub_categoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "output categories:\n",
      "\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "input categories:\n",
      "\t ['question_title', 'question_body', 'answer', 'sub_category']\n"
     ]
    }
   ],
   "source": [
    "output_categories = list(df_train.columns[11:])\n",
    "# input_categories = list(df_train.columns[[1,2,5]])#orogional code\n",
    "input_categories = list(df_train.columns[[1,2,5,10]]) # we added the sub_categoty!\n",
    "print('\\noutput categories:\\n\\t', output_categories)\n",
    "print('\\ninput categories:\\n\\t', input_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        \n",
    "        t = t[:t_new_len]\n",
    "        q = q[:q_new_len]\n",
    "        a = a[:a_new_len]\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q, a = _trim_input(t, q, a, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.valid_predictions.append(\n",
    "            self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n",
    "        \n",
    "        rho_val = compute_spearmanr(\n",
    "            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        \n",
    "        print(\"\\nvalidation rho: %.4f\" % rho_val)\n",
    "        \n",
    "        if self.fold is not None:\n",
    "            self.model.save_weights(f'bert-base-{fold}-{epoch}.h5py')\n",
    "        \n",
    "        self.test_predictions.append(\n",
    "            self.model.predict(self.test_inputs, batch_size=self.batch_size)\n",
    "        )\n",
    "\n",
    "def bert_model():\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments], outputs=out)\n",
    "    \n",
    "    return model    \n",
    "        \n",
    "def train_and_predict(model, train_data, valid_data, test_data, \n",
    "                      learning_rate, epochs, batch_size, loss_function, fold):\n",
    "        \n",
    "    custom_callback = CustomCallback(\n",
    "        valid_data=(valid_data[0], valid_data[1]), \n",
    "        test_data=test_data,\n",
    "        batch_size=batch_size,\n",
    "        fold=None)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    model.fit(train_data[0], train_data[1], epochs=epochs, \n",
    "              batch_size=batch_size, callbacks=[custom_callback])\n",
    "    \n",
    "    return custom_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f2ee62ce874864956b93fbe27c4d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bf022d0002435686aab7039c200340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=10).split(X=df_train.question_body, groups=df_train.question_body) ############## originaln_splits=10\n",
    "\n",
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "inputs = compute_input_arays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-96b2ba753a47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtrain_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-2e04cb9c9c74>\u001b[0m in \u001b[0;36mbert_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m         (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mbert_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBERT_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_word_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_segments\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m           _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_has_training_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_is_hub_module_v1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m     93\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m   \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_v1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m   \"\"\"\n\u001b[1;32m--> 519\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[0;32m    541\u001b[0m       loader = loader_cls(object_graph_proto,\n\u001b[0;32m    542\u001b[0m                           \u001b[0msaved_model_proto\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m                           export_dir)\n\u001b[0m\u001b[0;32m    544\u001b[0m       \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_info_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;31m# captures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_functions_structures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_functions_captures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m_setup_functions_captures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m                   \u001b[0mcustom_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_capture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mcustom_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_capture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[1;31m# Setting \"captures\" first means \"capture\" won't create a new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# placeholder for this input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\custom_gradient.py\u001b[0m in \u001b[0;36mcopy_handle_data\u001b[1;34m(source_t, target_t)\u001b[0m\n\u001b[0;32m     80\u001b[0m           \u001b[0mtarget_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m           \u001b[0mtarget_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m           shapes, ranks, types)\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    \n",
    "    # will actually only do 3 folds (out of 5) to manage < 2h\n",
    "    if fold < 3:\n",
    "        K.clear_session()\n",
    "        model = bert_model()\n",
    "\n",
    "        train_inputs = [inputs[i][train_idx] for i in range(3)]\n",
    "        train_outputs = outputs[train_idx]\n",
    "\n",
    "        valid_inputs = [inputs[i][valid_idx] for i in range(3)]\n",
    "        valid_outputs = outputs[valid_idx]\n",
    "\n",
    "        # history contains two lists of valid and test preds respectively:\n",
    "        #  [valid_predictions_{fold}, test_predictions_{fold}]\n",
    "        history = train_and_predict(model, \n",
    "                          train_data=(train_inputs, train_outputs), \n",
    "                          valid_data=(valid_inputs, valid_outputs),\n",
    "                          test_data=test_inputs, \n",
    "                          learning_rate=0, epochs=1, batch_size=10,\n",
    "                          loss_function='binary_crossentropy', fold=fold)\n",
    "\n",
    "        histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = [histories[i].test_predictions for i in range(len(histories))]\n",
    "# test_predictions = [np.average(test_predictions[i], axis=0) for i in range(len(test_predictions))]\n",
    "# test_predictions = np.mean(test_predictions, axis=0)\n",
    "\n",
    "# df_sub =df_sub.assign(results = test_predictions)\n",
    "# print(df_sub)\n",
    "# df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
